\documentclass[10pt, conference, compsocconf]{styles/IEEEtran}
\usepackage{cite}
\usepackage{balance}

\usepackage[pdftex]{graphicx}
\usepackage{grffile} % multiple dots in filename
\graphicspath{{figures/}}
\DeclareGraphicsExtensions{.pdf}

\usepackage[cmex10]{amsmath}
\interdisplaylinepenalty=2500
% \usepackage{algorithmic}
%\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{subfig}
\usepackage{wrapfig}

\usepackage{url}
\usepackage[usenames,dvipsnames]{color}

% should be loaded last (but before algorithm*) -colored links and refs
\usepackage[colorlinks=true, citecolor=OliveGreen, linkcolor=BrickRed, urlcolor=MidnightBlue, final, pdftex]{hyperref}
%\hypersetup
%{
%    pdfauthor={Authors},
%    pdfsubject={Subject},
%    pdftitle={Title},
%    pdfkeywords={Keywords}
%}

\usepackage{xspace}
\usepackage{algorithm}
\usepackage{algorithmic}

% \setlength{\parskip}{0ex}

%% Using watermark (this will mess up top/bottom margins)
%\usepackage{styles/pdfdraftcopy}
%\draftcolor{gray20}
%\draftstring{
%\begin{minipage}{17cm}
%\begin{center}
%\  DRAFT - \today\\Not approved for public release
%\end{center}
%\end{minipage}
%}
%\draftfontsize{36pt}

% Another option; doesn't clobber margins, but doesn't seem to like multiple lines

%\usepackage{draftwatermark}
%\SetWatermarkText{DRAFT of \today. Not approved for public release}
%\SetWatermarkScale{.2}
%\SetWatermarkColor[rgb]{0.7,0.7,0.7}

% custom commands
\newcommand{\etal}{{\em et al.}}
\newcommand{\naive}{na\"{\i}ve }
%\newcommand{\point}[1]{\vspace{2mm} \noindent\textbf{#1}}
\newcommand{\point}[1]{\noindent\textbf{#1}.}
\newcommand{\todo}[1]{\textbf{\color{red}[TODO: #1]}}
\newcommand{\rob}[1]{\textbf{\color{blue}[rob: #1]}}
\newcommand{\citeme}{\textbf{\color{red} {cite}}\xspace}
\renewcommand{\S}{Section~}
\newcommand{\Eg}{\emph{E.g.}}
\newcommand{\eg}{\emph{e.g.}}
\newcommand{\etc}{\emph{etc}}
\newcommand{\Ie}{\emph{I.e.}}
\newcommand{\ie}{\emph{i.e.}}
\newcommand{\paul}[1]{{\color{red}\em (Paul says: ``#1'')}}
\newcommand{\griffin}[1]{{\color{blue}\em (Griffin says: ``#1'')}}

\newcommand{\ps}{TAPS\xspace}
\newcommand{\compactify}{\settowidth{\labelsep}{o} \settowidth{\labelwidth}{o} \settowidth{\labelindent}{o}}

\title{Genuine onion: Simple, Fast, Flexible, and Cheap Website Authentication}
%\title{Simple, Fast, Flexible, and Cheap Website Authentication,
%  Integrity, and Traffic Security}

\author{
\IEEEauthorblockN{Paul Syverson}
\IEEEauthorblockA{U.S. Naval Research Laboratory\\
paul.syverson@nrl.navy.mil}
\and
\IEEEauthorblockN{Griffin Boyce}
\IEEEauthorblockA{Open Internet Tools Project\\
griffin@cryptolab.net}
}

\begin{document}

\maketitle

\begin{abstract}
  Use of Tor's .onion virtual domain has traditionally focused on
  offering hidden services, services that separate their reachability
  from the identification of their IP addresses. We argue that Tor's
  .onion system can be used to provide an entirely separate benefit:
  basic website authentication. We also argue that not only can
  onionsites provide website authentication, but doing so is easy,
  fast, cheap, flexible and secure when compared to alternatives such
  as TLS with certificates.
\end{abstract}

% \input{sections/abstract}
% \begin{IEEEkeywords}
% anonymity; throttling; experimentation; Tor;
% \end{IEEEkeywords}
% \input{sections/introduction}
% \input{sections/Brief background on Tor and .onion services}
% \input{sections/Knowing to which self to be true}
% \input{sections/Our onions ourselves}
% \input{sections/Considerations for Hidden Service Operators}
% \input{sections/performance}
% \input{sections/errors}
% \input{sections/propagation}
% \input{sections/related}
% \input{sections/conclusion}

\section{Introduction}
Tor is a widely popular communications infrastructure for anonymous
communication. Millions use its thousands of relays for unfettered
traffic-secure access to the Internet. The vast majority of Tor
traffic by bandwidth (over 99\% at our last check) is on circuits
connecting Tor clients to servers that are otherwise accessible.  Tor
also provides protocols for connecting to services on the
pseudo-top-level domain .onion, which are only accessible via Tor.

In this paper we explore using Tor's .onion infrastructure so that
individuals operating a website can create authentication, integrity
and other guarantees more simply, easily, fully, cheaply, and flexibly
than by relying on standard protocols and authorities.

Tor's onionsites have been advocated since their introduction as a
way to protect network location information for servers not just
clients~\cite{tor-design}. \footnote{Such advocacy actually predates
  their introduction inasmuch as the same was said for web servers
  contacted by reply onions~\cite{onion-routing:cacm99}, See
  also~\cite{rewebber} for description of an implemented predecessor
  to Tor's hidden services.}  Discussion in the popular press, as well
as research to date, has focused almost exclusively on location hiding
and associated properties provided by onionsites and the protocols
to interact with them. Indeed, these are generally referred to
collectively as \emph{Tor Hidden Services} in the research literature
and as the \emph{Dark Web} in the popular press. (Although so many
importantly distinct things are often subsumed and run together under
`Dark Web' as to rob the term of clear significance, other than as a
warning flag to watch out for the hidden incoherence that surrounds
most occasions of its use.)

Our intent is to challenge the narrowness of this view of
onionsites. In particular we will discuss security protections they
readily facilitate that are largely orthogonal to hiding server
location. We hope by the end of this paper, the reader will agree that
they should more properly be called \emph{onion services} or in any
case something that is more properly inclusive of the variety of
security properties they offer.

\section{Brief background on Tor and onion services}

We sketch out minimal basics of Tor onion services. For more detailed
descriptions see the Tor design paper or other documentation at the
Tor website~\cite{torproject}. For a high-level graphical description
of onion services see~\cite{tor-hs}. For a more up to date, and much
more technical, description of onion services protocols see the Tor
Rendezvous Specification~\cite{tor-rend-spec}.

Tor clients randomly select three of the roughly 6000 relays
comprising the current Tor network, and create a cryptographic circuit
through these to connect to Internet services. Since only the first
(entry guard) relay in the circuit sees the IP address of the client and
only the last (exit) relay sees the IP address of the destination,
this technique separates identification from routing.

To offer an onion service, a web (or other) server creates Tor circuits to
multiple \emph{Introduction Points} that await connection attempts
from clients. A user wishing to connect to a particular onion service
uses the .onion address to look up these Introduction Points in a
directory system. In a successful interaction, the client and
onionsite then both create Tor circuits to a client-selected
\emph{Rendezvous Point}. The Rendezvous Point mates their circuits
together, and they can then interact as ordinary client and server of
a web connection over this rendezvous circuit.

Since the onionsite only communicates over Tor circuits it creates,
this protocol hides its network location. And that is the feature that
gives it the name `hidden service'. But, there are other important
features to the .onion system, notably self-authentication. The .onion
address is actually the hash of the public key of the onionsite. For
example, if one wishes to connect to the DuckDuckGo search engine's
onion service, the address is 3g2upl4pq6kufc4m.onion. The Tor client
recognizes this as a .onion address and thus knows to use the above
protocol rather than attempting to pass the address through a Tor
circuit for DNS resolution at the exit. The public key
corresponds to the key that signs the list of of Introduction Points
and other service descriptor information provided by the directory
system. In this way, .onion addresses are self-authenticating.

\section{Knowing to which self to be true}

Of course this authentication only binds the service descriptor
information to the 3g2upl4pq6kufc4m.onion address. What a user would
like to be assured of is that s/he is reaching DuckDuckGo. Presumably
the user wants the search results DuckDucGo offers and not what might
be returned by some other, possibly malicious, server.  In addition to
the integrity guarantee, the user relies on authentication so that its
queries are revealed only to DuckDuckGo and not to others. The
.onion address by itself does not offer this.
Making use of the traditional web trust infrastructure, DuckDuckGo
offers a certificate for its .onion address issued by DigiCert.
Similarly, FaceBook offers a DigiCert certificate.

Though cryptographic binding is essential to the technical mechanisms
of trust, users also rely on human-readable familiarity, for example, that
their browser graphically indicates they have made a certified encrypted
connection as a result of typing facebook.com into the browser.  To
some extent, it is at least possible to make use of this in .onion
space. By generating many keys whose hash had `facebook' as initial
string and then looking among the full hashes for an adequately
felicitous result, Facebook was able to obtain facebookcorewwwi.onion
for its address. Whatever its value for Facebook, this is clearly not
something that will work widely.

Why not just obtain certificates from traditional authorities as
DuckDuckGo and Facebook have done? For many server operators, getting
even a basic server certificate is just too much of a hassle. The
application process can be confusing. It usually costs money. It's
tricky to install correctly. It's a pain to update. This is not 
original observation. Indeed that description is actually a quote
from the blog of
Let's Encrypt, a new certificate authority dedicated among other
things to making TLS certification free and automatic~\cite{lets-encrypt}.

As of this writing, Let's Encrypt is still a few months away
from offering their services.
Should they be willing to offer certificates for .onion
domains, using Let's Encrypt would be an easy way for
onionsite operators to take advantage of the traditional certification
infrastructure. Traditional certificates are not without problems,
however. The nature of the trust hierarchy is opaque to direct usage,
and the sheer number of trusted authorities is large enough to be of
concern. In particular, there have been numerous documented cases of
governmental man-in-the-middle attacks through certificate
manipulation and hacking of certificate authorities leading to use of
fraudulent certificates for some of the most popular websites.

The EFF's SSL Observatory~\cite{ssl-observatory} is designed to
monitor for such problems and document their occurrence, while
Google's Certificate Transparency
Effort~\cite{certificate-transparency} is a similar but broader
initiative that adds (amongst other things) append-only signed public
logs that make certificate shenanigans all the harder to bring off
undetectably.

Rather than simply monitor and make available certificate authority
problems, the Perspectives Project~\cite{perspectives}, through its
Firefox extension, strives to
provide end users with control over the trust they place in website
certificates. Improving user flexibility
and control is one of our goals as well. Instead of trusting
anointed CAs, semi-trusted network notaries probe network services and
build a record of public keys those services have used over time,
somewhat similar to the approach of certificate transparency. Users
can choose which notaries they wish to trust, and clients encountering
unfamiliar public keys will query notaries for a history of keys used
by a service~\cite{perspectives-paper}. This is especially intended to
enhance trust on first use (tofu) authentication, although it can also
supplement traditional CA based PKI security. While Perspectives
provides security over time for self-signed certificates, it is still
subject to tofu assumptions and dependent on the setup of an adequate
independent notary system.

\section{Our onions ourselves}

As noted, onionsites already provide a self-authenticated binding of
public key to onion address, but lack a way to bind that public key to
something familiar for the site in question.  Even for hidden
service applications, it might still be desired to connect the
onionsite to some sort of pseudonymous reputation.  For us, however,
the location hiding aspect is largely orthogonal.  We would like a solution
that will work for all kinds of sites, but we are especially
interested in providing authentication for small and/or short-lived
websites, e.g., personal web pages, hometown sports teams, sites for
local one-time events, small businesses, municipal election campaigns,
etc.  Though not such large targets as more popular sites, they are
still subject to controversy and have been subject to many of the same
sorts of attacks as more well-known sites.  They might also not be
the target of attacks but simply collateral victims. 

Some users of this kind may
not even have Internet accounts that allow them to set up
servers. Onionsites are compliant with such a limitation since they
actually only make outbound client connections. As a related
example of an existing usage, many people administering systems
behind restrictive firewalls that only permit outbound connections
currently use onion services to administer their systems.  Even if the
user has an Internet account that permits setting up a web page, HTTPS
may not be available from that provider or only available for an
additional fee.

Of course one can always create a Facebook page or something similar
that is protected by HTTPS and TLS certificates,
and this is often done.  But this makes the service dependent on the
reputation, trust, policies, and protections of such a host and the
dynamics thereof, rather than allowing the user to readily understand
and control these aspects of his own service. Also, Facebook
policy requires identification of the person providing the site
while we would prefer to leave this as simply a separate issue.

A very simple way to add binding of the onionsite public key to
a known entity using widely available mechanisms is to provide a
signature on the .onion address. We envision a PGP/GPG signature, but
it could be an X509 signature (or other as we discuss below). 
The signed text can simply be
included on the onionsite, making it self-authenticating in this sense
as well. The trust in the authentication will then be whatever trust
is associated with the public key that does the signing. Such
techniques are already used for signing code. For example,
the Tor Project offers signatures on all source and binaries
it makes available for download. 

If the signer wishes to post the signed .onion address to a public
site such as her Facebook page, s/he can do this also. (An advantage
of doing so will be discussed below.) Indeed, a
useful public site for doing this would be an unauthenticated version
of the same exact service as the one being offered at the onionsite.
The unauthenticated version and the onionsite version would be
identical, hence both would contain a signed pointer to the secure and
authenticated version, i.e., onionsite version. It is then
easy for anyone who desires to check if the unauthenticated version
matches the secure version. For example, we have made an authenticated
version of http://cupcakebridge.com available at http://eynfqhbaq5yecx6s.onion.

One might ask why to even bother with the non-onionsite version. There
are several reasons. First, this allows for a binding of the public
domain name to the onionsite. As mentioned, .onion addresses are
inherently not humanly meaningful, which can lead to confusion among 
end-users.  To get a the entirety of a specific domain name of choice is
technologically infeasible even then, as .onion addresses are
randomly-generated alphanumeric strings of 16 digits. The signed-onion
technique allows someone to choose and retain a desired domain name for the
site, while still being able to offer an authenticated and integrity
protected version easily. This also illustrates one of the pros
of using GPG or similar signatures. If the authentication simply
showed that the same party that provided the not-secured site
provided the onionsite, an attacker could set up an altered version,
employ usual techniques to hijack the not-secure site and offer
a self-authenticated onionsite that matched the hijacked site.
To do this undetectably against the GPG-signed onionsite would require
subversion of the trust in the GPG key. A con of using GPG signatures
is that many users of the onionsite may not be familiar with them,
have appropriate trust in the key, or bother to check. We will address
these below.

In addition, many intended users of the site may not have Tor installed.
Though installation is a simple point-and-click download, many may be
disinclined against even this small effort. The onionsite would still
be available via Tor2web, a website that proxies connections from
non-Tor clients to onionsites~\cite{tor2web}.  To connect to a .onion
address, one enter a URL such as the following for reaching
DuckDuckGo's onionsite via Tor2web:
https://3g2upl4pq6kufc4m.tor2web.org/ The Tor2web site explicitly
states that ``Tor2web only protects publishers, not readers.'' This is
because the client connects to Tor2web over a direct TLS connection
rather than via Tor, as would be the case of someone connecting to
3g2upl4pq6kufc4m.onion via the Tor Browser.  For our purposes,
authentication of the onionsite in this case is limited to the trust
in authentication of this TLS connection (and trust in Tor2web itself)
regardless of the trust in the GPG signature.

Finally, traditional search and indexing engines such as Google do
not generally reflect links to onionsites. While there is an onionsite
search engine, ahmia.fi~\cite{ahmia}, it is not well-known to
people unfamiliar with Tor's .onion services. It is also limited to
onionsites, so would not integrate results from the wider web.  And 
unlike traditional search engines such as Google, ahmia's results are 
opt-in rather than opt-out, leading to a skewed picture of the onion 
site ecosystem.
\paul{I don't think this is true. Ahmia's results come from
crawls of .onion space, not just from onionsites that have created
an opt-in.}

\section{Usability, Convenience, and Security}

What we have described so far implies a relatively manual
authentication of PGP/GPG signatures. It would be natural and
straightforward to create a plugin that verifies the signature
and provides different indications depending on the trust in it.
There are already related tools. For example, Enigform is a
Mozilla Firefox extension to support OpenPGP signed HTTP requests.
And various social trust visualization tools exist.

Our approach presents a natural complement to Perspectives.
Perspectives offers an improvement against
certificate based MitM attacks. But if a site is newly available
the onionsite can still be trusted to be bound to the signing
authority whereas a self-signed certificate will have little or no
Perspective history and users are reduced to effectively a tofu
decision. Also, Perspective notaries largely function as
detectors of certificate misbehavior. 
Thus if, e.g., a typo-squatting site uses a self-signed certificate to
pass through connections to the site on which it is squatting, but
does not misbehave or alter its key, Perspectives will not reflect
anything wrong with the sites, whereas our approach will presumably
not give the site a high degree of trust unless the squatter has
that trust from us exogenously.

Our approach also can be used (at least in manual form) right now by
website operators. While it can benefit from usability developments
and simplification and can complement other approaches. It does not
rely fundamentally on the deployment and continued commitment to new
infrastructure that is specifically for website authentication.  It
can rely on whatever authentication infrastructure might be popular
and likely to be maintained for independent reasons, rather than
needing to grow and maintain interest in its approach.

PGP and its successors also remain less familiar than TLS. For those
who do not obtain protection from its web of trust, TLS certificates
are likely to remain the primary ground of linking public, human
readable domain names to the signatures authenticating
websites. Assuming Let's Encrypt is successful, and HTTPS at no
additional cost is increasingly available from ISPs, we can also
envisage incorporation of TLS with onionsites for even the
``everyman'' users described above.  To the extent that this
incorporation follows what Facebook and DuckDuckGo have done, the
strength of trust in the authentication is limited by the trust in the
TLS certificate. Certificate transparency and the
like will help here, but the self-authentication of .onion addresses
can also add to this trust, and again in a way more directly under the
control of the website owner.

Unlike conventional web URLs, the .onion address is inextricably connected to
the site authentication key. This means that if one has publicized the
.onion address, e.g., through blogs, twitter, or Facebook, people
following those address links will not be vulnerable to hijack or MitM
by the subverted CA the way they would be by a link to a regular
URL\@. This significantly raises the bar on the hijacker fairly
automatically and easily.

If onionsite private keys sign not just the Introduction Points and
other elements currently stored in the .onion directory system, but
also the TLS certificate, this would give the website owner direct
control over the authentication of the TLS certificate that cannot be
bypassed by a simple up-hierarchy certificate hijack. Now the hijacker
would need to not only subvert some CA, he must also create and
propagate a new onion address and associated keys. Unless this
verification by .onion key of TLS key is also to be done manually,
this would involve either a change to the current .onion directory
protocols or another plugin, depending how it is done.

\section{Conclusion}

In this paper we have described how Tor's onion services can be used
not for the usual stated purpose of hiding server network location,
but for website authentication.  We have also argued that onion
services offer users, a simple, effective, cheap and flexible means of
authentication with security advantages not provided by existing
approaches. We hope people will find this useful and begin employing
it. We also hope this will encourage others to explore this
fascinating system for other interesting properties and applications.



Still to do: GSA use etc. ?



%\point{Acknowledgments}
% \section*{Acknowledgments}
% We thank the anonymous reviewers for their feedback and suggestions.

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{22}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}
 
\newcommand{\BIBdecl}{\setlength{\itemsep}{0\baselineskip plus 0.1\baselineskip minus 0.1\baselineskip}}
\balance
{\footnotesize 
\bibliographystyle{styles/IEEEtran}
\bibliography{references}
}

%\nocite{*}
 
%\clearpage
%\input{sections/appendix}

\end{document}


Furthermore, these are often the sorts of users least able to configure
and secure 





There are a number of problems and limitations with the existing
web authentication and certification infrastructure, most of which
we will not touch on. There are, however, several that can be
improved upon through use of onionsites.

Unlike TLS, key management is extremely straightforward for .onion
service operators, and key exchange is handled by the network itself.
The key size and cipher have rational defaults.  The downside is that
anyone with the key can impersonate an onion site, as the .onion
address is inextricably tied to its key.  An adversary who acquires a
TLS private key cannot impersonate a clearnet website, as the key is
unrelated to the domain name.


\section{Other Considerations for Hidden Service Operators}



