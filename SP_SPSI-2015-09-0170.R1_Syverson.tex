%\documentclass[10pt, conference, compsocconf]{styles/IEEEtran}
\documentclass[10pt]{styles/IEEEtran}
\usepackage{cite}
\usepackage{balance}



\usepackage[pdftex]{graphicx}
\usepackage{grffile} % multiple dots in filename
\graphicspath{{figures/}}
\DeclareGraphicsExtensions{.pdf}

\usepackage[cmex10]{amsmath}
\interdisplaylinepenalty=2500
% \usepackage{algorithmic}
%\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{subfig}
\usepackage{wrapfig}

\usepackage{url}
\usepackage[usenames,dvipsnames]{color}

% should be loaded last (but before algorithm*) -colored links and refs
\usepackage[colorlinks=true, citecolor=OliveGreen, linkcolor=BrickRed, urlcolor=MidnightBlue, final, pdftex]{hyperref}
%\hypersetup
%{
%    pdfauthor={Authors},
%    pdfsubject={Subject},
%    pdftitle={Title},
%    pdfkeywords={Keywords}
%}

\usepackage{xspace}
\usepackage{algorithm}
\usepackage{algorithmic}

% \setlength{\parskip}{0ex}

%% Using watermark (this will mess up top/bottom margins)
%\usepackage{styles/pdfdraftcopy}
%\draftcolor{gray20}
%\draftstring{
%\begin{minipage}{17cm}
%\begin{center}
%\  DRAFT - \today\\Not approved for public release
%\end{center}
%\end{minipage}
%}
%\draftfontsize{36pt}

% Another option; doesn't clobber margins, but doesn't seem to like multiple lines
%\usepackage{draftwatermark}
%\SetWatermarkText{DRAFT of \today. Not approved for public release}
%\SetWatermarkScale{.2}
%\SetWatermarkColor[rgb]{0.7,0.7,0.7}

\pagestyle{plain}

% custom commands
\newcommand{\etal}{{\em et al.}}
\newcommand{\naive}{na\"{\i}ve }
\newcommand{\point}[1]{\vspace{2mm} \noindent\textbf{#1}}
%\newcommand{\point}[1]{\noindent\textbf{#1}.}
\newcommand{\todo}[1]{\textbf{\color{red}[TODO: #1]}}
\newcommand{\rob}[1]{\textbf{\color{blue}[rob: #1]}}
\newcommand{\citeme}{\textbf{\color{red} {cite}}\xspace}
\renewcommand{\S}{Section~}
\newcommand{\Eg}{\emph{E.g.}}
\newcommand{\eg}{\emph{e.g.}}
\newcommand{\etc}{\emph{etc}}
\newcommand{\Ie}{\emph{I.e.}}
\newcommand{\ie}{\emph{i.e.}}
\newcommand{\paul}[1]{{\color{red}\em (Paul says: ``#1'')}}
\newcommand{\griffin}[1]{{\color{blue}\em (Griffin says: ``#1'')}}

\newcommand{\ps}{TAPS\xspace}
\newcommand{\compactify}{\settowidth{\labelsep}{o} \settowidth{\labelwidth}{o} \settowidth{\labelindent}{o}}


\title{Bake in .onion for Tear-free and Stronger Website Authentication}

\author{
\begin{tabular}[t]{c@{\extracolsep{8em}}c} 
Paul Syverson & Griffin Boyce\\
U.S. Naval Research Laboratory & Berkman Center for Internet \& Society\\
paul.syverson@nrl.navy.mil & griffin@cryptolab.net
\end{tabular}
}

%\IEEEauthorblockN{Paul Syverson}
%\IEEEauthorblockA{U.S. Naval Research Laboratory\\
%paul.syverson@nrl.navy.mil}
%\and
%\IEEEauthorblockN{Griffin Boyce}
%\IEEEauthorblockA{Berkman Center for Internet and Society\\
%griffin@cryptolab.net}
%}

\begin{document}

\maketitle


\begin{abstract}
  Tor is a communications infrastructure widely used for unfettered
  and anonymous access to Internet websites. Tor is also used to
  access sites on the reserved domain .onion.  The focus of .onion use
  and discussion has traditionally been on the offering of hidden
  services, services that separate their reachability from the
  identification of their IP addresses. We argue that Tor's .onion
  system can be used to provide an entirely separate benefit: basic
  website authentication. We also argue that not only can onionsites
  provide website authentication, but doing so can be easier, faster,
  cheaper, \emph{and more secure} than existing
  alternatives.  We illustrate this with a general manual technique
  based on PGP that can be used right now. We also set out an
  automated approach that can be integrated with traditional TLS
  certificates---provided that changes we argue for are made to the
  current rules limiting the kinds of certificates permissible for .onion
  addresses.  
\end{abstract}

\begin{IEEEkeywords}
Tor, TLS certificates, PGP, traffic security, authentication
\end{IEEEkeywords}


\section{Introduction}

Tor is a widely popular communications infrastructure for anonymous
communication. Millions use its thousands of relays for unfettered
traffic-secure access to the Internet. The vast majority of Tor
traffic by bandwidth (about 95\% at our last check) is on circuits
connecting Tor clients to servers that are otherwise
accessible on the Internet~\cite{hs-stats-report-2015}. Tor
also provides protocols for connecting to services on the
reserved top level domain .onion, which are only accessible via Tor.
In this paper we explore using Tor's .onion infrastructure so that
individuals operating a website can create authentication, integrity
and other guarantees more simply, easily, fully, and inexpensively
than by other currently available means.

Tor's onionsites have been advocated since their introduction as a way
to protect network location information for servers, not just
clients~\cite{tor-design}. (Such advocacy actually predates their
introduction inasmuch as the same was said for web servers contacted
by reply onions~\cite{onion-routing:cacm99}.)
Discussion in the popular press, as well as research to
date, has focused almost exclusively on location hiding and associated
properties provided by onionsites and the protocols to interact with
them. Indeed, these are generally referred to collectively as
\emph{Tor Hidden Services} in the research literature and as the
\emph{Dark Web} in the popular press. (Although so many importantly
distinct things are often subsumed and run together under `Dark Web'
as to rob the term of clear significance.
Ironically, as spies and criminals attack users from hiding spots
throughout the infrastructure on today's Internet, Tor's
authenticated routing overlay is often the only direct control and
only illumination users have of where their traffic goes.)

We intend to challenge the narrowness of this view of
onionsites. In particular we will focus on security protections they
readily facilitate that are largely orthogonal to hiding server
location and that are stronger and broader than those currently
available by other means. We hope by the end of this paper the reader
will agree that they should be called \emph{onion services} or at
least something more properly inclusive of the security properties
they offer.

\point{Overview}

After some basics on Tor and onion services, we
describe a limitation on their self-authentication protection: onion
addresses are not human-meaningful. Certificates for meaningful
registered domains have problems as well, however, many of which are
particularly disadvantageous to operators of smaller, less global, or
less permanent websites.  We next describe some of the concerns for
such sites and propose a solution based on PGP signatures that
combines the usable meaningfulness of registered domain names with the
stronger and broader authentication that onion services can
provide.  This solution is available immediately, albeit manually.
We also sketch prospects for its automation and integration
into typical-user experience.
Because TLS is widely used and its interfaces comparatively well
understood, we next propose a way to obtain this
combination of properties by leveraging traditional certificates.
This requires a change in certificate issuance regulations for onion
addresses.  We argue that, for our proposed design, such changes are
sensible.

We illustrate our points using three running examples
of current sites that are available both as ordinary registered-domain
websites and as onionsites. Facebook is a large company that
possesses a strong form of cert covering both its onion address and its
registered-domain. DuckDuckGo is a company that offers an
onion address and has a cert, but only for its registered domain name,
not for its onion address.  Finally, Glenn Sorrentino is an
individual who has both types of sites but no TLS cert of any kind.

\section{Brief background on Tor and onion services}

We sketch out minimal basics of Tor onion services. For further
descriptions see the Tor design paper~\cite{tor-design}, related
documentation at the Tor website~\cite{torproject}, or a high-level
graphical description of onion services~\cite{tor-hs}. The Tor
Rendezvous Specification~\cite{tor-rend-spec} provides a more up to
date, and much more technical, description of onion-service
protocols.

Tor clients randomly select three of roughly 6700 relays~\cite{tor-network-size}
comprising the current Tor network, and create a cryptographic circuit
through these to connect to Internet services. Since only the first
relay in the circuit sees the IP address of the client and
only the last (exit) relay sees the IP address of the destination,
this technique separates identification from routing.
To offer an onion service, a web (or other) server creates Tor circuits to
multiple \emph{Introduction Points} that await connection attempts
from clients. A user wishing to connect to a particular onion service
uses the onion address to look up these Introduction Points in a
directory system. In a successful interaction, the client and
onionsite then both create Tor circuits to a client-selected
\emph{Rendezvous Point}. The Rendezvous Point mates their circuits
together, and they can then interact as ordinary client and server of
a web connection over this rendezvous circuit.

Since a properly-configured onionsite only communicates over Tor
circuits it creates,
this protocol hides its network location, the feature that
gives it the name `hidden service'. But, there are other important
features to the .onion system, notably self-authentication. The onion
address is actually the hash of the public key of the onionsite. 
For example, if one wishes to connect to the DuckDuckGo search engine's
onion service, the address is 3g2upl4pq6kufc4m.onion. The Tor client
recognizes this as an onion address and thus knows to use the above
protocol rather than passing the address through a Tor
circuit for DNS resolution at the exit (which protects against leakage
of client interests by observation of a DNS lookup as well as against
any of the well-known DNS hijinks). The public key corresponds to the
key that signs the list of Introduction Points and other service
descriptor information provided by the directory system. In this way,
onion addresses are self-authenticating.


For services such as DuckDuckGo, the value provided by onion services
lies, not in their location hiding, but in this additional
authentication and in the greater assurance of improved route security
offered to their users by requiring a connection via Tor. The
complexity, latency, and network overhead of the several Tor circuits
needed to reach Introduction Points and Rendezvous Points is not
needed to provide those protections. There are nonetheless, also some
performance advantages to providing an onion service to the users
wishing to connect to one's site via Tor (e.g., skirting effects of
exit relay bandwidth scarcity). And Tor proposals (the Tor equivalent
of IETF RFCs) to standardize further simplified onion services without
location hiding are in the works. Facebook already uses such
simplifications in offering its onion service.

\section{Knowing to which self to be true}

Of course the self-authentication described above 
for DuckDuckGo only binds the
service descriptor information to the 3g2upl4pq6kufc4m.onion
address. What a user would like to be assured of is that s/he is
reaching DuckDuckGo. Presumably the user wants the search results
DuckDuckGo offers and not what might be returned by some other,
possibly malicious, server.  In addition to the integrity guarantee,
the user relies on authentication so that queries are revealed only to
DuckDuckGo and not to others. The onion address by itself does not
offer this. Making use of the traditional web trust infrastructure,
Facebook offers a certificate for its onion addresses
issued by DigiCert.  This helps ensure that users are not misled by
onionsites purporting to be official.

Though cryptographic binding is essential to the technical mechanisms
of trust, users also rely on human-readable familiarity, for example,
that the browser graphically indicates s/he has made a certified
encrypted connection as a result of typing facebook.com into the
browser.  To some extent, it is at least possible to make use of this
in onionspace. By generating many keys whose hash had `facebook' as
initial string and then looking among the full hashes for an
adequately felicitous result, Facebook was able to obtain
facebookcorewwwi.onion for its address. Whatever its value for
Facebook, this is clearly not something that will work widely, as it
is difficult to generate custom addresses in this way. 

The Onion Name System (OnioNS) attempts to respond to these concerns
by creating a system for globally-unique but still human-meaningful
names for onionsites~\cite{vickers-onions}.  This has the advantage of
not being dependent on any existing naming scheme, such as existing
domain registration. On the other hand, through much experience and
design, existing approaches to naming have evolved effective usage and
infrastructure that we can leverage. We will focus herein on
approaches that link onion addresses to already meaningful ways of
referring to sites. In particular, we focus on the case where one controls
a registered domain name; although binding to other meaningful
web locations (such as a Facebook page or WordPress blog) is also possible.

If one has a registered domain name,
why not just obtain certificates from traditional authorities as
Facebook has done? For many server operators, getting
even a basic server certificate is just too much of a hassle. The
application process can be confusing. It usually costs money. It's
tricky to install correctly. It's a pain to update. 
These are not original observations. Indeed that description is
actually a quote from the blog of Let's Encrypt, a new certificate
authority dedicated, among other things, to making TLS certification
free and automatic for most websites~\cite{lets-encrypt}. 

Using the existing X.509 system, setting up a certificate can take
hours or even days. In cases where the website is operated by a
collective or organization, SSL/TLS certificates have been known to
take months, due to questions around ownership and authorization.
This time cost is in addition to the monetary cost of the certificate, if any.
In contrast, setting up an onionsite takes a few minutes and costs
nothing. Once Tor is installed, you simply add two lines to your torrc file 
and start Tor. The Tor Project also provides a brief page with
additional tips and advanced options~\cite{hs-config}.  Even if
one follows the option described below of PGP for the binding, and the process
of learning how to create a PGP key and signature is taken into
account, the time investment is dramatically less than with the
current X.509 public-key infrastructure.

As of this writing, Let's Encrypt services are still only available in
beta release.
Should they be willing to offer certificates for onion
domains, Let's Encrypt could be an easy way for
onionsite operators to take advantage of the traditional certification
infrastructure. We will return to this below.

Traditional SSL certificates have more problems than
the above cost and convenience questions. The trust
hierarchy is opaque to direct usage, and the sheer number of trusted
authorities is large enough to be of concern. In particular, there
have been numerous cases of man-in-the-middle (MitM) attacks through
certificate manipulation, as well as hacking of certificate
authorities or certificate validation software leading to use of
fraudulent certificates for some of the most popular
websites~\cite{forged-ssl-oakland14}.


EFF's SSL Observatory~\cite{ssl-observatory} 
monitors for such problems and documents their occurrence.
Google's Certificate Transparency
Effort~\cite{certificate-transparency} is similar but broader,
adding (amongst other things) append-only signed public
logs that make certificate shenanigans all the harder to bring off
undetectably.

The problems with certificates raised above and below, though real,
are largely moot at the moment for most of those who might wish
to create onion services. As of this writing,
the CA/Browser Forum has approved only EV (Extended Validation)
Certificates for .onion addresses. This limits their use to those with
the significant amount of time, money, and desire to follow the
extensive identity validation process required.  EV Certificates are
primarily used by large businesses~\cite{wikipedia-ev}. More common
for individuals, organizations, and small business that obtain
certificates for their sites are Domain Validation (DV) Certs. These
typically require a simple email confirmation based on information in
the WHOIS database.  

Further, the .onion top-level domain itself was without official status until
recently, which is part of why the approval to issue EV Certs was initially
temporary. An IETF RFC reserving .onion as one of the handful of
special-use domain names was, however, approved in October 2015 as a
proposed standard~\cite{ietf-onion-tld-rfc}.  With the official
release of this RFC, the approval of certs for .onion addresses is now
on firmer footing~\cite{7686-and-all}. 


\section{Our onions ourselves}
\label{ourselves}

As noted, onionsites already provide a self-authenticated binding of
public key to onion address but do not bind that public key to
something recognizably associated with that site.  We seek a solution
that will work for all kinds of sites, but in this section we are
especially interested in providing authentication for only moderately
popular and/or short-lived websites, e.g., personal web pages,
hometown sports teams, sites for local one-time events, small
businesses, municipal election campaigns, etc.  Though not such large
targets as more popular long-lived sites, they are still subject to
controversy and have been subject to many of the same sorts of attacks
as more well-known sites.  They might also not be the target of
attacks but simply collateral victims.

Some users of this kind may not even have Internet accounts that allow
them to set up servers. Onionsites are generally compliant with such a
limitation since they actually only make outbound client
connections. A related existing usage is for
administering systems behind restrictive firewalls that only permit
outbound connections.  Even if the user has an Internet account that
permits setting up a web page, HTTPS may not be available from that
provider or only available for an additional fee.

Website owners may also wish to simply make sure their sites are
available to Tor users. With a growing userbase already in the
millions, this is understandable.  Some sites, such as Facebook, use an
onion service to provide better performance, security, and user
experience for Tor users than they are able to offer simply having
those users connect to their site over a simple Tor circuit connecting
to facebook.com~\cite{7686-and-all}. On the other hand, those with a
small personal site may discover that access to it from Tor exits is
blocked by their hosting provider.  Thus, when Glenn Sorrentino, a
product designer, realized this was true of his site glennsorrentino.com,
he set up a version of that site on a small personal system at
at3o24mj2rfabkca.onion. This provides other benefits as well, but his
motivation was to allow reachability for Tor users. (Since the Tor network
is designed to be reached even by users experiencing censorship,
another possible way to solve this same problem would be to run the
site as an onion service from the same web server but
connecting to Tor via bridges and obfuscating pluggable
transports~\cite{bridges}.)

We are primarily focused on improvements to authentication using
onionsites and thus mostly leave properties of network location hiding
aside as orthogonal to our goals. They can be complementary, however.
Authenticated
hidden services are also an appealing option for those who'd like to
secure their onionsites for personal use.  Unlike traditional websites
that appear online prior to authentication, users lacking
authentication information for such a site will not be easily able to
determine that it even exists, nor will they be able to probe it for
vulnerabilities.  These qualities make an ideal environment for
operating a personal cloud service.  With privacy and cost in mind,
many people are operating their own cloud infrastructure to store
files and calendar entries using open-source systems such as Cozy and
OwnCloud~\cite{cozy}.  Another common use of authenticated hidden
services is as a personal RSS reader, as onionsites ensure some level
of feed integrity (particularly important when fetching news feeds
that do not utilize TLS).

One can always create a Facebook page or something similar
that is protected by HTTPS and TLS certificates,
and this is often done.  But this makes the service dependent on the
reputation, trust, policies, and protections of such a host, not to mention
the dynamics thereof, rather than allowing the user to readily understand
and control these aspects of his own service. 

A very simple way to add binding of the onionsite public key to
a known entity using widely available mechanisms is to provide a
signature on the onion address, such as a PGP/GPG signature.
The signed text can be
included on the onionsite, making it self-authenticating in this sense
as well. The trust in the authentication will then be whatever trust
is associated with the public key that does the signing. Such
techniques are already used for signing code. For example,
the Tor Project offers signatures on all source and binaries
it makes available for download. 

If the signer wishes, she can also post the signed onion address to a
public site such as her Facebook page (An advantage of doing so will
be discussed below.) Indeed, a useful public site for
doing this would be an unauthenticated version of the same exact
service as the one being offered at the onionsite.  The
unauthenticated version and the onionsite version should both contain
a signed pointer to both versions. It is then easy for anyone who
desires to check their association.  For example, by posting his PGP
signature on both addresses at both
http://glennsorrentino.com/onion-binding.php and
http://at3o24mj2rfabkca.onion/onion-binding.php Glenn Sorrentino binds
the addresses of the insecure and authenticated versions of his site.

Another natural place to post the association would be to Keybase,
which is in beta and a somewhat similarly motivated ``people
directory''~\cite{keybase}. Keybase lets one look up via usernames on
github, reddit, twitter, bitcoin etc.\ identifiers signed with the
same PGP key. Keybase is, incidentally, another commercial site with
an onion address (http://fncuwbiisyh6ak3i.onion/) for its
registered-domain address (https://keybase.io/), although at last
check they have not recursively listed this itself within Keybase.

Given the authentication benefits onionsites provide, why even bother
with a non-onionsite version? 
Providing a site at the registered domain is a way
to make it available to users not coming over Tor.
An onionsite could typically still be accessed via Tor2web, a website
that proxies connections from non-Tor clients to
onionsites~\cite{tor2web}.  But, whatever availability such proxying
services provide, they inherently operate as at best an overtly
acknowledged man-in-the-middle on connections to onionsites.  Since we
are focused on not merely maintaining but improving authentication in
this paper, we will say no more about such possibilities. We thus
limit ourselves to \emph{secure} onionsite access for the millions of
current Tor users and those who become users. Site operators wishing to
provide access more widely if less securely should do so via connection
to the registered domain name---hopefully at least protected by HTTPS.

Finally, traditional search and indexing engines such as Google do not
generally reflect links to onionsites. One can get them to list
onionsites associated with registered domains by including these in
site metadata, as in our running example of glennsorrentino.com.
The search engine
ahmia.fi~\cite{ahmia} is limited to onionsites and known primarily to
those familiar with them. Ahmia creator Juha Nurmi has, however,
agreed to incorporate linking of onion and registered-domain addresses into
Ahmia, together with the GPG signatures binding that linking.  He has
also suggested to us that Ahmia could automatically test the
signatures and check the registered-domain and onion sites. Thus, a user who
trusts Ahmia (and her connection to Ahmia) on this can verify that a
pair of websites is operated by the same party, even if personally
inexpert with manual PGP verification. Crawling and indexing of
onionsites is also in its infancy and can thus not be expected to be
as appropriately representative as the much more mature indexing of
the surface web by Google and similar sites.

\section{Usability, Convenience, and Security}

As most onionsite visitors use the Tor Browser, deployment and
debugging of hidden services can be faster than their registered-domain
counterparts because there is only one browser to test, with only
minor variation across users.  Website operators can assume that users
do not have AdBlock or other browser extensions that may impact how
content is displayed.  However, plugins that may mitigate Tor
Browser's privacy protections, such as Java and Flash, have been
disabled by default.  Many privacy-conscious users do enable the
NoScript extension to block javascript as well.  Despite this, rich
content such as video, audio, and interactive storytelling are still
available for designers willing to use HTML5 and CSS3.
And since Tor Browser is generally somewhat more restricted than other
browsers in what it will process, if operators do wish to offer access
to their Tor-Browser-tested site at a registered domain, no change
should typically be needed for successful access using other browsers.

What we have described so far implies a relatively manual
authentication of PGP/GPG signatures. It would be natural and
straightforward to create a plugin that verifies the signature and
provides different indications to the user depending on the trust in
it.  There are already related tools, e.g., Monkeysphere, a Firefox
plugin that uses the PGP trust infrastructure for validation only when
the browser does not default accept the TLS certificate
validation~\cite{monkeysphere}. A simpler plugin could also
just check the planned Ahmia validation mentioned above.

Our PGP approach also can be used (at least in manual form) right now by
website operators. It would benefit from usability developments
and simplification, and it can complement other approaches. It does not,
however,
rely fundamentally on the deployment and continued commitment to new
infrastructure that is specific to it.  It can instead
rely on whatever authentication infrastructure might be popular
and likely to be maintained for independent reasons, rather than
needing to grow and maintain interest in its approach.

In the PGP web of trust, signature authority is built up in a
decentralized manner from direct personal connections and
introductions. This more naturally fits with many of the kinds of
websites that we have suggested could most benefit from our approach,
for which local or personal trust relationships are
important~\cite{zimmerman}.  The X.509 trust model currently in
general use to support TLS certificates is by contrast primarily a
hierarchical centralized chain of trust delegated down from some
ultimate national or global corporate trust anchor.

PGP remains much less familiar than
TLS\@. Popular familiarity is, however, not so much with TLS as with
interfaces that tell the user little more than whether or not TLS 
and certs from default accepted authorities are
in operation at all, which is roughly as it should be for usable
security. As noted, similar interfaces for PGP have been designed but
have not yet received the extensive development of TLS interfaces,
unsurprising given the fundamental role of TLS in global ecommerce.
For those who do not otherwise rely on the social or local protections
of PGP's web of trust, TLS certificates are likely to remain the
primary ground of linking public, human-readable domain names to the
signatures authenticating websites.


\section{Let's Authenticate}
\label{lets-auth}

Unlike conventional web URLs, onion addresses are inextricably
connected to the site authentication key. Thus, if one has
publicized the onion address, e.g., through blogs, Twitter, or
Facebook, people following those address links will not be vulnerable
to hijack or MitM by a subverted CA, as they would be by a link
to a registered-domain URL\@. 
This significantly raises the bar on the hijacker
fairly automatically and easily. Further, non-CA-based MitM techniques
such as forcing the site to fall back to a non-SSL version (e.g.,
SSLStrip) or to use a weaker cipher to communicate (e.g, BEAST and
FREAK) are also not possible as the address and key are inextricably
linked and generated cryptographically. 

Assuming Let's Encrypt is successful, we can envisage eventual
incorporation of TLS with onionsites for even the ``everyman'' users
described above.  While certificate transparency and the like will
help increase trust in authenticating such sites via their
certificates, the self-authentication of onion addresses also adds to
this trust: in the conventional sense that certificate transparency
addresses, in authentication of the route not just the destination,
and both of these in a way more directly under website owner control. 
But, it is not just the little guy. We have already noted a few of the
increasing number of prominent companies that offer onion
services. Also, the General Services Administration negotiates
federal-friendly Terms of Service amendments for the rest of the U.S.\
government~\cite{gsa-tos}. As of this writing, it is negotiating a
federal-friendly amendment for the current Let's Encrypt ToS
agreement.

In addition to the PGP-based approach given above,
we now sketch a description of incorporating onion addresses into
certificates for registered domains. We also describe how to
incorporate these into a relatively transparent and simple system for
website access with improved security. 

\point{Creating the Domain Validation Certificate}

We assume the cert to be obtained will have the onion address listed
as a SAN (subjectAltName) in the certificate issued for the registered
domain name.  This is currently ruled out for most by CA/Browser Forum policy,
which only allows registered domain names and wildcards thereof, such
as *.duckduckgo.com. The only exception is for EV
certificates.  As noted above, these are prohibitive for many site
owners, hence problematic. Nonetheless, DigiCert has provided instructions
for ordering .onion certs, in response to a large volume of
requests~\cite{digicert-onion-blog}.
We will explore below some of the concerns
and reasons why the novel approach herein supports a change from the
current restrictions.
But first we describe how this approach will work, assuming
onion addresses are allowed as names in DV certs in the setting
we describe.

(One could simply create a self-signed certificate with this binding of
onion and registered domain names. A pop-up would then warn users
going to the site because the signing authority is not trusted by the
browser.  Such warnings are important, especially since the
overwhelming majority of current Tor usage is for safer connections to
registered-domain addresses. And, in this section we pursue a
strengthening of, not an alternative to, the current authority-based
web authentication infrastructure. This centrally includes the user
experience thereof. We thus want to avoid both accepting self-signed
certs without warning and adding to circumstances where pop-up
warnings superfluously occur.)

At least the same DV level of checking should occur as is currently
done when issuing certificates to registered domain names. The latest
ballot-approved CA/B Forum Baseline Requirements list several ways
that control of a domain can be demonstrated~\cite{cabforum-br}.  The
most familiar is probably via response to email to
administrator@[registered domain] or similar address.
The Baseline Requirements also permit
that the applicant for a certificate can demonstrate the ability
to make a requested change, e.g. adding a nonce, to a
page under a domain name that terminates in the requested domain name. 
So, a  validation query protocol can be used
that freshly connects to the onionsite and asks if it is acceptable to
certify association of the onionsite with the registered domain.  This
can also serve as a check that an onionsite the user just set up is
properly configured and thus the certification process can continue.
Only if all DV checks complete successfully should the CA be willing
to issue the Cert.


An email or other check of the registered domain must also include the
onion name that is being bound as well as the registered domain name.
If someone were to obtain a certificate for multiple registered domain
names by showing control of only one, they could thereby fraudulently
authenticate others covered by the certificate. The
self-authentication of onion addresses limits this damage.  This check
alone would not prevent someone from obtaining certificates for onion
addresses not under her control. But, since she would not possess the
private key for the onion address, people thereby tricked into going
to that address thinking it was authenticated by the cert or thereby
associated with the registered domain name would simply experience a
failure to successfully complete a connection. Nonetheless, many
subtle attacks on authentication are possible when parties are
confused about who they are connecting to and in what role, especially
if authentication protocol runs are interleaved~\cite{fosad00}.  It is
therefore advisable to have a similar check that someone with control
over the onion address authorizes binding of the registered domain
name to the onion address.


\point{Connecting to an onionsite by the client}

Assuming an onionsite has been configured and certificate issued for
it, how should a client connect to the onionsite? If connection
to the onion address has been requested, e.g., by the user
clicking on a link to that address, then the connection should
proceed as normal and the browser should display appropriately for a
DV-certified destination. But a client may request a connection
to the registered-domain address associated in the certificate
and be automatically redirected to the onionsite as a security
enhancement. This could be done by additions to the HTTPS Everywhere
ruleset.

HTTPS Everywhere is a browser extension incorporated by default in Tor
Browser and currently available for Firefox, Chrome, and
Opera~\cite{https-everywhere}. It rewrites requests to visit sites via
unencrypted HTTP to HTTPS requests. This does more than simply add an
``S'' to the request. Sometimes the encrypted version of a site and
the unencrypted version are at different locations in the domain.
Conversely, sometimes adding an ``S'' to an HTTP request will
succeed, but will connect to a page intended by the domain owner for an
entirely different purpose than offering a secure version of the site
at the unencrypted address.  Like HSTS, HTTPS Everywhere also helps
guard against SSLStrip and similar attacks. HTTPS Everywhere
also includes the SSL Observatory mentioned above.
(Though it would be a much more significant difference from current HTTPS
Everywhere, note that the ruleset could be expanded to allow redirection
to onionsites that are using the GPG approach to binding described
above.)

Another advantage of relying on HTTPS Everywhere for directing
registered-domain requests to onionsites is that there will
be no DNS lookup of IP address associated with the domain name.
This means that no attacks on DNS resolution or even observations
of DNS lookups exiting the Tor network can affect such connections.

\point{An onion by any other name would cert as sweet}

Why not permit onion addresses as names in certificates in the above
setting? Two broad classes of objections have been raised to us in
CA/B Forum discussions and discussions with CA/B Forum members.

First, currently deployed onion addresses and protocols rely on SHA-1
and RSA-1024, both of which are recognized to have reached their
effective cryptographic security end-of-life. But, Tor client and
relay software has already transitioned in stable releases to SHA-256
and ed25519, which are generally accepted as adequate for the
foreseeable future. And Tor is expected to transition onion services
to these within the year. So any valid objections based on this
concern must be very short-lived.  More importantly, when combined as
described above, onion protections can only add to the
protections offered by TLS and certificates. Breaking the
private RSA-1024 key associated with an onion address that has an
appropriately stronger TLS key and cert does not by itself allow one
to subvert a certified TLS session with the onionsite. Conversely,
MitM, cipher degradation, or other attacks on the cert or TLS instance
are not possible when connecting to an onion address unless one also breaks
the self-authentication.

Second, for various reasons there is some desire to support CA's being
able to link ``real-world'' identities to issued certificates as
occurs when validating registered domain names, which is why only EV
certs have been approved for onion addresses. But the above only
proposes that DV certs for onion addresses be issued when fully bound
to a registered domain name by the same validation that would permit
the cert issuance for the registered domain name; whatever benefits
such linking provides is just as strongly supported for the onion
address as would be supported when issuing a cert for the registered
domain name by itself.

\section{Conclusion}

In this paper we have described how Tor's onion services can be used,
not for the usual stated purpose of hiding server network location,
but for website authentication.  We have also described how securely
combining onion services with registered domains allows site operators
to offer a simple, effective, and inexpensive means of providing
authentication with security advantages not currently otherwise
available. We have described two approaches to this: One, based on
PGP, is feasible for immediate albeit manual use.
%and works generally to provide authentication for any human-meaningful
%site identifier.  
The other enhances existing authority-based TLS and has the potential
for simple setup and use in conjunction with the Let's Encrypt
infrastructure.

A decade ago, websites available via encrypted and authenticated
connections were relatively rare, rather than ubiquitous as they are
today.  At the time, the need to provide users with such options
seemed the province of the paranoid rather than standard good
practice. Whether or not our specific design recommendations are
adopted, we hope readers can see in our proposals similar prospects
for general adoption in the years to come of the stronger and broader
authentication and confidentiality offered by onionsites. We also hope
our expanded view of the possibilities created by Tor's onion services
will encourage others to explore this fascinating system for other
interesting properties and applications.


\point{Acknowledgments.}
% \section*{Acknowledgments}
We thank the anonymous reviewers for their feedback and suggestions.
We have also benefited from conversations with many people including
Richard Barnes, Roger Dingledine, Peter Eckersley, Eric Mill, Alec
Muffett, Mike Perry, Seth Schoen, and Ryan Sleevi.


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{22}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}
 
%\newcommand{\BIBdecl}{\setlength{\itemsep}{0\baselineskip plus 0.1\baselineskip minus 0.1\baselineskip}}
\balance
%{\footnotesize 
\bibliographystyle{styles/IEEEtran}
%\bibliography{references}
%}

%\nocite{*}

% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{hs-stats-report-2015}
G.~Kadianakis and K.~Loesing, ``Extrapolating network totals from
  hidden-service statistics,'' The Tor Project, Tor Tech Report 2015-01-001,
  January 2015.

\bibitem{tor-design}
R.~Dingledine, N.~Mathewson, and P.~Syverson, ``{Tor: The Second-Generation
  Onion Router},'' in \emph{Proceedings of the 13th USENIX Security Symposium},
  August 2004.

\bibitem{onion-routing:cacm99}
D.~M. Goldschlag, M.~G. Reed, and P.~F. Syverson, ``{Onion Routing for
  Anonymous and Private Internet Connections},'' \emph{Communications of the
  ACM}, vol.~42, no.~2, pp. 39--41, February 1999.

\bibitem{torproject}
``{The Tor Project},'' \url{https://www.torproject.org/}.

\bibitem{tor-hs}
``{Tor: Hidden Services Protocol},''
  \url{https://www.torproject.org/docs/hidden-services.html.en}.

\bibitem{tor-rend-spec}
``{Tor Rendezvous Specification},''
  \url{https://gitweb.torproject.org/torspec.git/tree/rend-spec.txt}.

\bibitem{tor-network-size}
``Tor network size,'' \url{https://metrics.torproject.org/networksize.html}.

\bibitem{vickers-onions}
J.~Vickers, ``{OnioNS} -- the onion name system,''
  \url{https://github.com/Jesse-V/OnioNS-server}.

\bibitem{lets-encrypt}
``{Let's Encrypt: Delivering SSL/TLS Everywhere},''
  \url{https://letsencrypt.org/2014/11/18/announcing-lets-encrypt.html},
  November 2014.

\bibitem{hs-config}
``{Configuring Hidden Services for Tor},''
  \url{https://www.torproject.org/docs/tor-hidden-service.html.en}.

\bibitem{forged-ssl-oakland14}
L.-S. Huang, A.~Rice, E.~Ellingsen, and C.~Jackson, ``{Analyzing Forged SSL
  Certificates in the Wild},'' in \emph{IEEE Symposium on Security and Privacy
  (SP), 2014}, May 2014, pp. 83--97.

\bibitem{ssl-observatory}
``{The EFF SSL Observatory},'' \url{https://www.eff.org/observatory}.

\bibitem{certificate-transparency}
``{Certificate Transparency},'' \url{http://www.certificate-transparency.org/}.

\bibitem{wikipedia-ev}
``Extended validation certificate,''
  \url{https://en.wikipedia.org/wiki/Extended_Validation_Certificate}.

\bibitem{ietf-onion-tld-rfc}
J.~Appelbaum and A.~Muffett, ``The .onion special-use domain name,''
  \url{https://tools.ietf.org/html/rfc7686}, 2015.

\bibitem{7686-and-all}
A.~Muffett, ``{RFC} 7686 and all that \ldots,''
  \url{https://www.facebook.com/notes/alec-muffett/rfc-7686-and-all-that/10153809113970962},
  2015.

\bibitem{bridges}
``Tor bridges,'' \url{https://www.torproject.org/docs/bridges}.

\bibitem{cozy}
``{Cozy: a Personal Cloud You can Host, Hack and Delete},''
  \url{http://cozy.io/}.

\bibitem{keybase}
``Keybase,'' \url{https://keybase.io}.

\bibitem{tor2web}
``{Tor2web: browse the anonymous internet},'' \url{https://www.tor2web.org/}.

\bibitem{ahmia}
``{Tor Hidden Service (.onion) search: Ahmia.fi},''
  \url{https://ahmia.fi/search/}.

\bibitem{monkeysphere}
``Monkeysphere,'' \url{http://web.monkeysphere.info/}.

\bibitem{zimmerman}
P.~Zimmerman, ``{Why OpenPGP's PKI is better than an X.509 PKI},''
  \url{http://www.openpgp.org/technical/whybetter.shtml}, February 2001.

\bibitem{gsa-tos}
{U.S. General Services Administration}, ``List of negotiated terms of service
  agreements,''
  \url{https://www.digitalgov.gov/resources/negotiated-terms-of-service-agreements/}.

\bibitem{digicert-onion-blog}
{Ordering a .Onion Certificate from DigiCert},
  \url{https://blog.digicert.com/ordering-a-onion-certificate-from-digicert/}.

\bibitem{cabforum-br}
``{CA/Browser Forum Baseline Requirements Certificate Policy for the Issuance
  and Management of Publicly-Trusted Certificates, Version 1.3.0},''
  \url{https://cabforum.org/wp-content/uploads/CAB-Forum-BR-1.3.0.pdf}.

\bibitem{fosad00}
P.~Syverson and I.~Cervesato, ``The logic of authentication protocols,'' in
  \emph{Foundations of Security Analysis and Design: Tutorial Lectures},
  R.~Focardi and R.~Gorrieri, Eds.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer-Verlag, LNCS 2171, 2001, pp. 63--136.

\bibitem{https-everywhere}
{HTTPS Everywhere}, \url{https://www.eff.org/https-everywhere}.

\end{thebibliography}


\begin{IEEEbiographynophoto}{Paul Syverson}
  is Mathematician at the U.S. Naval Research Laboratory, Center for
  High Assurance Computer Systems. His research is predominantly in
  computer and communications security and privacy with an emphasis on
  theory, design, and analysis of traffic-secure systems, especially
  all things onion routing.  He holds an AB in philosophy from Cornell
  University and an MA and PhD in philosophy and MA in mathematics,
  all three from Indiana University. He is an EFF Pioneer, a Foreign
  Policy Global Thinker, and a Fellow of the ACM.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Griffin Boyce}
  is a Fellow at the Berkman Center for Internet \& Society at Harvard
  University as well as a Senior Censorship Researcher for the Open
  Internet Tools Project. He works on a variety of anti-censorship
  projects, ncluding Satori, a tamper-resistant distribution project
  for circumvention tools, and Cupcake Bridge, a Chrome add-on that
  allows web browsers to expand access to the Tor network.
\end{IEEEbiographynophoto}


 
%\clearpage
%\input{sections/appendix}

\end{document}
